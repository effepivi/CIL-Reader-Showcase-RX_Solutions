{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0624249a-4426-46eb-a6b8-2303aa92b288",
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "#   Copyright 2025 UKRI-STFC\n",
    "\n",
    "#   Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "#   you may not use this file except in compliance with the License.\n",
    "#   You may obtain a copy of the License at\n",
    "\n",
    "#   http://www.apache.org/licenses/LICENSE-2.0\n",
    "\n",
    "#   Unless required by applicable law or agreed to in writing, software\n",
    "#   distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "#   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "#   See the License for the specific language governing permissions and\n",
    "#   limitations under the License.\n",
    "#\n",
    "# Authors:\n",
    "# Franck Vidal (URKI-STFC)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02005f77-361f-425c-835a-48094c6fd6cc",
   "metadata": {},
   "source": [
    "# RXSolutionsReader Laminography Demo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f144e2c1-b1f0-43ab-831e-7b3f4ee7a683",
   "metadata": {},
   "source": [
    "## Data format: RX Solutions\n",
    "\n",
    "The data is in the format used by devices made by [RX Solutions](https://www.rx-solutions.com/en). The projections are saved in TIFF files. They are flatfield corrected using 16-bit unsigned integers. Metadata is saved in two different files, an XML file that can be used with orbital geometries, and a CSV file that can be used with flexible geometries."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57bd9719-6fdd-4750-8864-ef3954e5d450",
   "metadata": {},
   "source": [
    "## CIL Version\n",
    "\n",
    "This notebook was developed using CIL v25.0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c5b1523-96d1-40d4-9c97-af643293cd5a",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "The data is available from Zenodo: https://doi.org/10.5281/zenodo.??????\n",
    "\n",
    "It is a laminography dataset of ???. \n",
    "It was acquired with the ???? platform developed by [RX Solutions](https://www.rx-solutions.com/en) for the [MATEIS Laboratory](https://mateis.insa-lyon.fr/en) of [INSA-Lyon](https://www.insa-lyon.fr/en/)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d44897e4-3741-4ecb-9640-b1603f988282",
   "metadata": {},
   "source": [
    "Update this filepath to where you have saved the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cbdcfa7-4619-4a60-88ec-5d14bf1845a7",
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "data_path = \"/DATA/CT/2025/DTHE\"\n",
    "number_of_slices_to_reconstruct = 500 # Use 0 to compute it automatically\n",
    "pixel_pitch_in_mm = (0.15,0.15)\n",
    "scaling_factor = 3\n",
    "first_angle=360\n",
    "last_angle=0\n",
    "\n",
    "# data_path = \"/DATA/CT/2025/RX_Solutions/suzanne_circular\"\n",
    "# number_of_slices_to_reconstruct = 0 # Use 0 to compute it automatically\n",
    "# pixel_pitch_in_mm = (0.5,0.5)\n",
    "# scaling_factor = 3\n",
    "# first_angle=0\n",
    "# last_angle=360\n",
    "\n",
    "file_path = os.path.join(data_path, 'unireconstruction.xml')\n",
    "# file_path = os.path.join(data_path, 'geometry.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1277d410-1038-4d01-b2e7-2f942002dc71",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import gc\n",
    "\n",
    "from cil.utilities.display import show2D, show_geometry, show_system_positions\n",
    "from cil.processors import TransmissionAbsorptionConverter, Slicer, CentreOfRotationCorrector\n",
    "from cil.framework import ImageGeometry\n",
    "from cil.plugins.astra import FBP\n",
    "from cil.utilities.jupyter import islicer, link_islicer\n",
    "from cil.io.TIFF import TIFFWriter\n",
    "\n",
    "import torch\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "print(\"Device:\", device)\n",
    "\n",
    "from cil.optimisation.functions import Function\n",
    "import deepinv\n",
    "\n",
    "from readers.RXSolutionsDataReader import RXSolutionsDataReader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8674b999-78f4-49d7-8754-b65f84469179",
   "metadata": {},
   "source": [
    "# Loading Geometry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "451e58e4-9dad-4ad5-8513-63434e6d1132",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaling_factor = 3\n",
    "\n",
    "if scaling_factor == 1:\n",
    "    roi = None\n",
    "else:\n",
    "    roi = {\"axis_1\": [None, None, scaling_factor], \"axis_2\": [None, None, scaling_factor]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "983813c5-4772-4253-9370-ca1feef27598",
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = RXSolutionsDataReader(XML_file_path, pixel_pitch_in_mm=pixel_pitch_in_mm, first_angle=first_angle, last_angle=last_angle, last_angle_included=False, roi=roi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c6a20b6-b866-46f2-a3bd-10a266c4c00f",
   "metadata": {},
   "outputs": [],
   "source": [
    "acq_geom = reader.get_geometry()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eb8c195-ad8a-4736-8033-f0bf36997c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "if acq_geom.geom_type != \"CONE_FLEX\":\n",
    "    show_geometry(acq_geom)\n",
    "else:\n",
    "    show_system_positions(acq_geom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d79c4183-d9ff-4a94-99a5-e4480b4d5dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(acq_geom)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4896b95-f3df-4f6f-8dc1-16b5b2a75bc1",
   "metadata": {},
   "source": [
    "# Loading Projections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe283c61-ae1b-41c6-8a64-0dd0a5d4dd69",
   "metadata": {},
   "outputs": [],
   "source": [
    "acq_data = reader.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76b35215-f6bd-4c18-a904-f53adb7c7428",
   "metadata": {},
   "outputs": [],
   "source": [
    "show2D(acq_data, origin='upper-left');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cc23efc-770c-4d15-b10f-b12e025727eb",
   "metadata": {},
   "source": [
    "# Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b3a3a25-db61-4fc5-8712-29cfdbd2012c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_exp = TransmissionAbsorptionConverter()(acq_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5aaa32c-74dd-400c-8a12-00b0f8818e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "if acq_geom.geom_type != \"CONE_FLEX\":\n",
    "    processor = CentreOfRotationCorrector.image_sharpness(\"centre\", \"tigre\")\n",
    "    processor.set_input(data_exp)\n",
    "    data_corr = processor.get_output()\n",
    "else:\n",
    "    data_corr = data_exp\n",
    "\n",
    "# Prepare the data for Astra\n",
    "data_corr.reorder(order='astra')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba32bf88-2d73-4a75-b9dd-268ee9657372",
   "metadata": {},
   "outputs": [],
   "source": [
    "if acq_geom.geom_type != \"CONE_FLEX\":\n",
    "    image_geometry = data_corr.geometry.get_ImageGeometry()\n",
    "        \n",
    "    image_geometry.voxel_size_x = min(image_geometry.voxel_size_x, image_geometry.voxel_size_y, image_geometry.voxel_size_z)\n",
    "    image_geometry.voxel_size_y = image_geometry.voxel_size_x\n",
    "    image_geometry.voxel_size_z = image_geometry.voxel_size_x\n",
    "else:\n",
    "    # Use the system magnification to compute the voxel size\n",
    "    mag = data_corr.geometry.magnification\n",
    "    mean_mag = np.mean(mag)\n",
    "    print(\"Mean magnification: \", mean_mag)\n",
    "    \n",
    "    voxel_size_xy = data_corr.geometry.config.panel.pixel_size[0] / mean_mag\n",
    "    voxel_size_z = data_corr.geometry.config.panel.pixel_size[1] / mean_mag\n",
    "    \n",
    "    # Create an image geometry\n",
    "    num_voxel_xy = int(np.ceil(data_corr.geometry.config.panel.num_pixels[0]))\n",
    "    num_voxel_z = int(np.ceil(data_corr.geometry.config.panel.num_pixels[1]))\n",
    "    \n",
    "    image_geometry = ImageGeometry(num_voxel_xy, num_voxel_xy, num_voxel_z, voxel_size_xy, voxel_size_xy, voxel_size_z)\n",
    "\n",
    "if number_of_slices_to_reconstruct > 0:\n",
    "    image_geometry.voxel_num_z = number_of_slices_to_reconstruct // scaling_factor\n",
    "\n",
    "print(image_geometry)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80a4f66d-65bf-4d5e-9fa3-038ee3447428",
   "metadata": {},
   "source": [
    "# Using a FDK for the reconstruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd399bb0-085d-4314-b19b-9ce351f2fc0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reconstruct using FDK\n",
    "# Instantiate the reconsruction algorithm\n",
    "fdk = FBP(image_geometry, data_corr.geometry)\n",
    "fdk.set_input(data_corr)\n",
    "\n",
    "# Perform the actual CT reconstruction\n",
    "FDK_recon = fdk.get_output()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eb6c5a3-9ddd-449a-aae2-cd01939a5a0a",
   "metadata": {},
   "source": [
    "## Release memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f5f270f-2d19-4a98-a57a-b575db63e2a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "del data_exp\n",
    "del acq_data\n",
    "del reader\n",
    "\n",
    "gc.collect();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ecb1526-3082-47d8-a75c-a9f6340bd103",
   "metadata": {},
   "source": [
    "## Save the reconstruction as a stack of TIFF files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bb6b1db-efd6-4634-92de-a92dc164799c",
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = TIFFWriter(FDK_recon, os.path.join(data_path, \"FDK-recon/slice\"))\n",
    "writer.write()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdfadd02-803b-4273-9251-1918f0941908",
   "metadata": {},
   "source": [
    "## Visualise the reconstruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac96d4d4-e248-4299-a962-ae4433f51d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "islicer(FDK_recon)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "818118b7-d3ed-45b1-9f85-089c49212f61",
   "metadata": {},
   "source": [
    "# Using TV regularised least squares solved with FISTA for the reconstruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21e96c66-dea8-45bf-ae06-e027d53752fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cil.plugins.astra import ProjectionOperator\n",
    "from cil.optimisation.functions import LeastSquares\n",
    "from cil.plugins.ccpi_regularisation.functions import FGP_TV\n",
    "from cil.optimisation.algorithms import FISTA\n",
    "\n",
    "projector = ProjectionOperator(image_geometry, data_corr.geometry)\n",
    "LS = LeastSquares(A=projector, b=data_corr)\n",
    "\n",
    "alpha = 0.05\n",
    "TV = FGP_TV(alpha=alpha, nonnegativity=True, device='gpu')\n",
    "fista_TV = FISTA(initial=FDK_recon, f=LS, g=TV, update_objective_interval=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4e79ca9-0619-4923-aef9-30c158506642",
   "metadata": {},
   "outputs": [],
   "source": [
    "fista_TV.objective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26e471d5-188e-4ef0-a06c-9f9297dc77ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "fix_range = (FDK_recon.min(), FDK_recon.max())\n",
    "\n",
    "for i in range(4):\n",
    "    fista_TV.run(25,verbose=1)\n",
    "    show2D(fista_TV.solution, title = 'Iteration {}'.format(i*25), fix_range=fix_range, origin='upper-left', size=(5,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "827c33e2-981e-41e6-a7f1-409e6b33e798",
   "metadata": {},
   "outputs": [],
   "source": [
    "TV_recon = fista_TV.solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "245f9f90-b025-4284-9c67-31dd8fe327d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "del fista_TV\n",
    "del TV\n",
    "\n",
    "gc.collect();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09651f79-c407-40b1-a200-d9fffd6945de",
   "metadata": {},
   "source": [
    "## Save the reconstruction as a stack of TIFF files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c98f272-2178-4c9f-a45e-5e6e243fd2a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = TIFFWriter(TV_recon, os.path.join(data_path, \"TV-recon/slice\"))\n",
    "writer.write()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d78d25e-b4a7-4517-bd4a-3b3645158b21",
   "metadata": {},
   "source": [
    "## Visualise the reconstruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "438e628f-d840-4c80-b4ee-7f9731521aa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "islicer(TV_recon)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd982834-92e2-43c2-84e5-39814fb31f50",
   "metadata": {},
   "source": [
    "# Compare the two reconstructions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72977f23-fd3a-4325-b658-340c07c026da",
   "metadata": {},
   "outputs": [],
   "source": [
    "half_number_of_slices = FDK_recon.shape[0] // 2\n",
    "\n",
    "show2D([FDK_recon, TV_recon], origin='upper-left', fix_range=fix_range, slice_list=(('vertical',half_number_of_slices // 2)))\n",
    "show2D([FDK_recon, TV_recon], origin='upper-left', fix_range=fix_range, slice_list=(('vertical',half_number_of_slices)))\n",
    "show2D([FDK_recon, TV_recon], origin='upper-left', fix_range=fix_range, slice_list=(('vertical',half_number_of_slices + half_number_of_slices // 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e97ad49d-251a-4c9e-925f-c87a163c1d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "link_islicer(islicer(FDK_recon), islicer(TV_recon))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4e422d6-681d-4141-a00b-57dc16dfead2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e318648-6391-4f87-976d-ea51fcbf67a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6e959c5-b832-47e4-bf74-ebe477fc9df5",
   "metadata": {},
   "outputs": [],
   "source": [
    "row_id = FDK_recon.shape[1] // 2\n",
    "plt.plot(FDK_recon.as_array()[half_number_of_slices//2, row_id], label=\"FDK\")\n",
    "plt.plot(TV_recon.as_array()[half_number_of_slices//2, row_id], label=\"TV\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "row_id = FDK_recon.shape[1] // 2\n",
    "plt.plot(FDK_recon.as_array()[half_number_of_slices, row_id], label=\"FDK\")\n",
    "plt.plot(TV_recon.as_array()[half_number_of_slices, row_id], label=\"TV\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "row_id = FDK_recon.shape[1] // 2\n",
    "plt.plot(FDK_recon.as_array()[half_number_of_slices + half_number_of_slices//2, row_id], label=\"FDK\")\n",
    "plt.plot(TV_recon.as_array()[half_number_of_slices + half_number_of_slices//2, row_id], label=\"TV\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "# islicer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f049207-9d5c-4889-85d9-1e9f2d98e344",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ea44a7a-a6af-4dad-b9aa-0a24bb0e66d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75bd7c46-5813-454f-a1be-92a915864854",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class DenoiserProximal(Function):\n",
    "    \"\"\"\n",
    "    DenoiserProximal is a custom CIL function that, when evaluated (__call__), returns 0. \n",
    "    It implements a proximal operator via a torch-based denoiser. When the\n",
    "    proximal() method is called, the input CIL data container is converted into a PyTorch\n",
    "    tensor, processed with the denoiser  using the specified noise level (tau), and then\n",
    "    wrapped back into a CIL data container.\n",
    "\n",
    "    Parameters:\n",
    "        denoiser: The torch-based denoiser which accepts an input tensor and a noise level.\n",
    "        device: The torch device (e.g., 'cuda' or 'cpu') on which the denoiser runs.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, denoiser, device='cuda'):\n",
    "        self.device = torch.device(device)\n",
    "        self.denoiser = denoiser \n",
    "        super(DenoiserProximal, self).__init__()\n",
    "\n",
    "    def __call__(self, x):\n",
    "        # This function merely returns 0 as its evaluation.\n",
    "        return 0 \n",
    "\n",
    "    def cil_to_torch(self, x):\n",
    "        \"\"\"\n",
    "        Convert a CIL data container to a PyTorch tensor.\n",
    "\n",
    "        This method extracts the 'array' attribute from the input CIL data container,\n",
    "        moves the data to the designated device, and adjusts the tensor's shape by squeezing\n",
    "        out the first dimension and adding a channel dimension. This reshaped tensor is then\n",
    "        ready to be passed to the denoiser denoiser.\n",
    "\n",
    "        Parameters:\n",
    "            x: A CIL data container with an 'array' attribute containing the data.\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: A PyTorch tensor formatted for the denoiser denoiser.\n",
    "        \"\"\"\n",
    "        return (torch.tensor(x.array, device=self.device)\n",
    "                .squeeze(0).unsqueeze(1))\n",
    "    \n",
    "    def torch_to_cil(self, x_tens, out):\n",
    "        \"\"\"\n",
    "        Convert a PyTorch tensor to a CIL data container.\n",
    "\n",
    "        After the denoiser processes the input, this method converts the resulting PyTorch tensor\n",
    "        back into the format expected by a CIL data container. It performs a reverse of the shaping operations\n",
    "        applied in cil_to_torch (i.e., removing the channel dimension and adding back the batch dimension)\n",
    "        and updates the 'array' attribute of the output container.\n",
    "\n",
    "        Parameters:\n",
    "            x_tens (torch.Tensor): The processed tensor from the denoiser.\n",
    "            out: A pre-allocated CIL data container to store the final output data.\n",
    "        \"\"\"\n",
    "        out.array[:] = (x_tens.squeeze(1).unsqueeze(0)\n",
    "                        .detach().cpu().numpy())\n",
    "            \n",
    "    def proximal(self, x, tau, out=None):\n",
    "        \"\"\"\n",
    "        Apply the proximal operator via a torch-based denoiser to a CIL data container.\n",
    "\n",
    "        This method implements the proximal step by first converting the input CIL data container\n",
    "        to a PyTorch tensor using cil_to_torch. The tensor is then passed to the denoiser along\n",
    "        with the provided noise level 'tau'. The output tensor is converted back into a CIL data container using\n",
    "        torch_to_cil. If no output container is provided (i.e., out is None), a new container is allocated\n",
    "        based on the geometry of x.\n",
    "\n",
    "        Parameters:\n",
    "            x: The input CIL data container to be processed.\n",
    "            tau (float): A scalar noise level parameter passed to the denoiser.\n",
    "            out: (Optional) A pre-allocated CIL data container for returning the result. If not provided,\n",
    "                 a new container is allocated.\n",
    "\n",
    "        Returns:\n",
    "            A CIL data container containing the denoiser-processed data.\n",
    "        \"\"\"\n",
    "        if out is None: \n",
    "            out = x.geometry.allocate(None)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            x_torch = self.cil_to_torch(x)\n",
    "            x_torch = self.denoiser(x_torch, tau)\n",
    "            self.torch_to_cil(x_torch, out)\n",
    "        return out \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c481b695-4ac2-491d-9d41-8229537afadd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DenoiserProximal3D(DenoiserProximal ):\n",
    "    \n",
    "    def __init__(self, denoiser, device='cuda:1'):\n",
    "\n",
    "\n",
    "        super(DenoiserProximal3D, self).__init__(denoiser, device)\n",
    "\n",
    "    def proximal(self, x, tau, out=None): \n",
    "        if out is None: \n",
    "            out = x.geometry.allocate(None)\n",
    "\n",
    "\n",
    "        with torch.no_grad():\n",
    "            x_torch = self.cil_to_torch(x)\n",
    "            \n",
    "            x_torch = self.denoiser(x_torch, tau)\n",
    "            \n",
    "            x_torch = x_torch.permute( 2, 1, 0, 3 ) #permute\n",
    "            x_torch= self.denoiser(x_torch, tau)\n",
    "            x_torch = x_torch.permute( 2, 1, 0, 3 ) #permute back\n",
    "        \n",
    "            x_torch = x_torch.permute( 3, 1, 2, 0 ) #permute\n",
    "            x_torch= self.denoiser(x_torch, tau)\n",
    "            x_torch = x_torch.permute( 3, 1, 2, 0 ) #permute back\n",
    "            \n",
    "            self.torch_to_cil(x_torch, out)\n",
    "        return out \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff301f8e-d3fe-4414-97bc-c05892308918",
   "metadata": {},
   "outputs": [],
   "source": [
    "denoiser = deepinv.models.DRUNet(in_channels=1, out_channels=1, pretrained='download', device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03fc08c9-9e68-4da0-8928-1de86cb532a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "x0 = FDK_recon \n",
    "lamb=500\n",
    "Regulariser = lamb*DenoiserProximal3D(denoiser, device)\n",
    "FISTA_DRUNet3D = FISTA(f=LS, \n",
    "                  g=Regulariser, \n",
    "                  initial=x0 ,\n",
    "                  update_objective_interval = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dc42a78-e0aa-443e-8b01-31bb8b3566e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(4):\n",
    "    FISTA_DRUNet3D.run(25,verbose=1)\n",
    "    show2D(FISTA_DRUNet3D.solution, title = 'Iteration {}'.format(i*25), fix_range=fix_range, origin='upper-left', size=(5,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca8c2974-9b83-4071-853d-714d83bf3bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "DRUNet3D_recon = FISTA_DRUNet3D.solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3de95e6a-13b4-449e-b3b7-d52bd905310a",
   "metadata": {},
   "outputs": [],
   "source": [
    "row_id = FDK_recon.shape[1] // 2\n",
    "plt.plot(FDK_recon.as_array()[half_number_of_slices//2, row_id], label=\"FDK\")\n",
    "plt.plot(TV_recon.as_array()[half_number_of_slices//2, row_id], label=\"TV\")\n",
    "plt.plot(DRUNet3D_recon.as_array()[half_number_of_slices//2, row_id], label=\"DRUNet3D\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "row_id = FDK_recon.shape[1] // 2\n",
    "plt.plot(FDK_recon.as_array()[half_number_of_slices, row_id], label=\"FDK\")\n",
    "plt.plot(TV_recon.as_array()[half_number_of_slices, row_id], label=\"TV\")\n",
    "plt.plot(DRUNet3D_recon.as_array()[half_number_of_slices, row_id], label=\"DRUNet3D\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "row_id = FDK_recon.shape[1] // 2\n",
    "plt.plot(FDK_recon.as_array()[half_number_of_slices + half_number_of_slices//2, row_id], label=\"FDK\")\n",
    "plt.plot(TV_recon.as_array()[half_number_of_slices + half_number_of_slices//2, row_id], label=\"TV\")\n",
    "plt.plot(DRUNet3D_recon.as_array()[half_number_of_slices + half_number_of_slices//2, row_id], label=\"DRUNet3D\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "# islicer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbc23e28-892a-4732-8243-a8f4d7f7cdd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "show2D([FDK_recon, TV_recon, DRUNet3D_recon], origin='upper-left', fix_range=fix_range, size=(5,5), slice_list=(('vertical',half_number_of_slices // 2)))\n",
    "show2D([FDK_recon, TV_recon, DRUNet3D_recon], origin='upper-left', fix_range=fix_range, size=(5,5), slice_list=(('vertical',half_number_of_slices)))\n",
    "show2D([FDK_recon, TV_recon, DRUNet3D_recon], origin='upper-left', fix_range=fix_range, size=(5,5), slice_list=(('vertical',half_number_of_slices + half_number_of_slices // 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8de687f-e91b-4367-afa1-ee7069427d34",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
